\documentclass[a4paper,11pt]{article}
\usepackage[polish]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{titlesec}

% Konfiguracja geometrii strony
\geometry{a4paper, total={170mm,257mm}, left=20mm, top=20mm}

% Wymuszenie przecinka jako separatora dziesiętnego w trybie matematycznym
\DeclareMathSymbol{,}{\mathord}{letters}{"3B}

% Ustawienia sekcji dla zwięzłości
\titleformat{\section}{\large\bfseries}{\thesection}{1em}{}
\titleformat{\subsection}{\normalsize\bfseries}{\thesubsection}{1em}{}

% Dane dokumentu
\title{\textbf{Dokumentacja końcowa projektu UMA}}
\author{Jan Szwagierczak, Tomasz Okoń}
\date{\today}

\begin{document}

\maketitle

\section{Treść zadania}
„Połączenie lasu losowego z SVM w zadaniu klasyfikacji. Postępujemy tak jak przy tworzeniu lasu losowego, tylko pewien procent klasyfikatorów w lesie to SVM. Jeden z klasyfikatorów (SVM lub drzewo ID3) może pochodzić z istniejącej implementacji.”


\section{Algorytmy i struktura rozwiązania}

W projekcie zaimplementowano hybrydowy zespół klasyfikatorów (\textit{Ensemble Learning}), łączący autorską implementację drzewa decyzyjnego ID3 z bibliotecznym klasyfikatorem SVM.

\subsection{Autorskie drzewo ID3}
Zaimplementowany algorytm ID3 buduje drzewo decyzyjne metodą zachłanną, wykorzystując Zysk Informacyjny (\textit{Information Gain}) jako kryterium podziału zbioru w każdym węźle.

Dla zbioru treningowego $S$, miara nieuporządkowania $H(S)$ oraz zysk informacyjny $IG(S,A)$ dla atrybutu $A$ definiowane są następująco:
\[
H(S) = - \sum_{i=1}^{k} p_i \log_2(p_i), \quad IG(S, A) = H(S) - \sum_{v \in Values(A)} \frac{|S_v|}{|S|} H(S_v)
\]
gdzie $p_i$ to prawdopodobieństwo wystąpienia $i$-tej klasy, a $S_v$ to podzbiór przykładów, dla których atrybut $A$ przyjmuje wartość $v$.

Procedura budowy drzewa jest rekurencyjna: w każdym kroku wybierany jest atrybut maksymalizujący $IG$, a zbiór dzielony jest na podzbiory, aż do uzyskania jednorodności klas w liściach lub wyczerpania atrybutów.

\subsection{Support Vector Machine (SVM)}
Jako drugi klasyfikator bazowy wykorzystano implementację liniowego SVM z biblioteki \texttt{scikit-learn}. Model poszukuje hiperpłaszczyzny maksymalizującej margines między klasami, realizując funkcję decyzyjną $f(x) = \operatorname{sign}(w^T x + b)$.
Proces uczenia polega na minimalizacji funkcji kosztu:
\[
\frac{1}{2}||w||^{2}+C\sum_{i}\xi_{i},
\]
gdzie parametr $C$ reguluje kompromis między szerokością marginesu a błędami klasyfikacji. Dla problemów wieloklasowych zastosowano strategię \textit{One-vs-Rest}.

\subsection{Algorytm Lasu Hybrydowego}
Algorytm zespołu wprowadza losowość na dwóch poziomach: danych (Bagging) oraz cech (Random Subspace Method). Procedura uczenia dla $T$ estymatorów przebiega następująco:
\begin{enumerate}
    \item Dla każdego estymatora $i=1 \dots T$:
    \begin{itemize}
        \item Losowana jest próba bootstrapowa $D_i$ (ze zwracaniem) o liczności równej liczności zbioru oryginalnego.
        \item Losowany jest podzbiór $m$ cech spośród wszystkich dostępnych (\textit{Random Subspace}), który jest wykorzystywany przez dany model.
        \item Z prawdopodobieństwem $p_{svm}$ trenowany jest klasyfikator SVM, w przeciwnym razie ($1-p_{svm}$) budowane jest drzewo ID3.
    \end{itemize}
    \item Predykcja dla nowej próbki odbywa się poprzez głosowanie większościowe wszystkich modeli zgromadzonych w lesie.
\end{enumerate}

\subsection{Odstępstwa i doprecyzowanie implementacji}
W stosunku do pierwotnych założeń wprowadzono jedno istotne doprecyzowanie wynikające z fazy implementacji:
\begin{itemize}
    \item Random Subspace Method:

    Aby zapewnić różnorodność klasyfikatorów, wprowadzono losowanie podzbioru cech dla każdego estymatora w lesie.

    Wartość $m$ (liczba cech używanych przez pojedynczy klasyfikator) ustawiono na $\sqrt{M}$, gdzie $M$ to całkowita liczba cech w zbiorze danych. Pozwoliło to na zwiększenie różnorodności modeli i poprawę ogólnej wydajności lasu.
\end{itemize}

\subsection{Weryfikacja poprawności (Testy)}
Aby upewnić się, że implementacja nie zawiera błędów, przeprowadzono:
\begin{enumerate}
    \item \textbf{Testy jednostkowe:} sprawdzono poprawność obliczania entropii (porównanie z wynikiem ręcznym dla prostego zbioru), poprawność podziałów w drzewie oraz mechanizm głosowania.
    \item \textbf{Porównanie z metodą referencyjną:} wyniki autorskiego drzewa ID3 porównano z \\ \texttt{DecisionTreeClassifier} (kryterium entropii) na zbiorze \textit{Mushroom}. Uzyskano zgodność wyników (dokładność $\approx 100\%$), co potwierdza poprawność logiki budowy drzewa.
\end{enumerate}

\section{Metodyka badań}

\subsection{Zbiory danych}
Do badań wykorzystano cztery zbiory danych o zróżnicowanej charakterystyce (tabela~\ref{tab:zbiory}). Zbiór \textit{Mushroom} pełni funkcję weryfikacyjną. Zbiory ciągłe (\textit{Breast Cancer}, \textit{Wine}) zostały poddane dyskretyzacji dla algorytmu ID3, a zbiory dyskretne (\textit{Car}) zakodowane metodą One-Hot dla SVM.

\begin{table}[H]
    \centering
    \caption{Charakterystyka zbiorów danych}
    \label{tab:zbiory}
    \begin{tabular}{lcccc}
        \toprule
        \textbf{Nazwa zbioru} & \textbf{Liczba przykładów} & \textbf{Liczba cech} & \textbf{Typ cech} & \textbf{Liczba klas} \\
        \midrule
        Mushroom & 8124 & 22 & Kategoryczne & 2 \\
        Wisconsin Breast Cancer & 569 & 30 & Ciągłe & 2 \\
        Wine Quality (Red) & 1599 & 11 & Ciągłe & 2 \\
        Car Evaluation & 1728 & 6 & Kategoryczne & 4 \\
        \bottomrule
    \end{tabular}
\end{table}

Liczebność klas w zbiorach:
\begin{itemize}
    \item Mushroom: 4208 (edible), 3916 (poisonous) - zbalansowany.
    \item Breast Cancer: 357 (benign), 212 (malignant) - lekko niezbalansowany.
    \item Wine Quality: 1382 (low quality), 217 (high quality) - silnie niezbalansowany. Zastosowano binaryzację na podstawie progu jakości \texttt{quality} $\geq 7$.
    \item Car Evaluation: 1210 (unacc), 384 (acc), 69 (good), 65 (vgood) - bardzo niezbalansowany
\end{itemize}
\subsection{Procedura eksperymentalna}
Każdy eksperyment przeprowadzono zgodnie z poniższymi zasadami, aby zapewnić rzetelność wyników:
\begin{itemize}
    \item Weryfikacja poprawności: Przed głównymi eksperymentami przeprowadzono testy jednostkowe i porównania z implementacjami referencyjnymi.
    \item Wielokrotne uruchomienia: Każdy punkt pomiarowy to średnia z 25 niezależnych uruchomień (różne ziarna losowości dla podziału zbioru i inicjalizacji lasu).
    \item Podział danych: Zastosowano 5-krotną walidację krzyżową (5-fold Stratified CV).
    \item Miary jakości: Raportowana jest średnia dokładność (Accuracy), odchylenie standardowe, najlepszy i najgorszy wynik oraz zagregowane macierze pomyłek.
\end{itemize}

\section{Wyniki eksperymentów}

\subsection{Weryfikacja}
W celu weryfikacji poprawności implementacji porównano wyniki autorskiego drzewa ID3 oraz modelu hybrydowego z implementacjami referencyjnymi z biblioteki \texttt{scikit-learn}: \texttt{DecisionTreeClassifier} (SkTree) oraz \texttt{RandomForestClassifier} (SkRF).

\begin{table}[H]
    \centering
    \caption{Porównanie dokładności implementacji autorskich z referencyjnymi}
    \label{tab:verification}
    \begin{tabular}{lccccc}
        \toprule
        \textbf{Zbiór danych} & \textbf{ID3} & \textbf{SkTree} & \textbf{Hybrid} & \textbf{SkRF} & \textbf{H-RF Diff} \\
        \midrule
        Mushroom & 1,0000 & 1,0000 & 0,9996 & 1,0000 & $-0,0004$ \\
        Breast Cancer & 0,9240 & 0,9240 & 0,9532 & 0,9415 & $+0,0117$ \\
        Wine Quality & 0,7554 & 0,7662 & 0,6810 & 0,8149 & $-0,1338$ \\
        Car Evaluation & 0,9383 & 0,9750 & 0,7784 & 0,9692 & $-0,1908$ \\
        \bottomrule
    \end{tabular}
\end{table}

\textbf{Wnioski:} Autorska implementacja ID3 osiąga identyczne wyniki jak \texttt{DecisionTreeClassifier} na zbiorze Mushroom (1,0000) oraz Breast Cancer (0,9240), co potwierdza poprawność algorytmu. Model hybrydowy przewyższa las losowy na zbiorze Breast Cancer ($+1,17$ p.p.), natomiast na zbiorach z cechami kategorycznymi (Car Evaluation) oraz silnie niezbalansowanych (Wine Quality) ustępuje implementacji referencyjnej - co jest zgodne z oczekiwaniami dla liniowego SVM.

\subsection{Scenariusz 1: Wpływ udziału SVM w lesie ($p_{svm}$)}
Zbadano wpływ parametru $p_{svm} \in \{0, 20, 50, 80, 100\}\%$. Parametr ten determinuje, jak duża część lasu składa się z klasyfikatorów SVM (reszta to ID3). W eksperymencie ustalono liczbę estymatorów $T=20$ oraz parametr regularyzacji SVM $C=1{,}0$.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{plots/scenario1_p_svm_mushroom_data_set.png}
        \caption{Mushroom}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{plots/scenario1_p_svm_wisconsin_breast_cancer.png}
        \caption{Breast Cancer}
    \end{subfigure}

    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{plots/scenario1_p_svm_wine_quality___red.png}
        \caption{Wine Quality}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{plots/scenario1_p_svm_car_evaluation.png}
        \caption{Car Evaluation}
    \end{subfigure}
    \caption{Średnia dokładność w zależności od udziału SVM ($p_{svm}$) dla $T=20$ oraz $C=1{,}0$. Słupki błędów oznaczają odchylenie standardowe.}
    \label{fig:psvm}
\end{figure}

\begin{table}[H]
    \centering
    \caption{Szczegółowe wyniki dla zbioru \textbf{Wisconsin Breast Cancer} (średnia z 25 uruchomień)}
    \begin{tabular}{ccccc}
        \toprule
        \textbf{$p_{svm}$ [\%]} & \textbf{Średnia Dokładność} & \textbf{Odch. Std.} & \textbf{Min} & \textbf{Max} \\
        \midrule
        0 (Czyste ID3) & 0,945 & 0,006 & 0,938 & 0,958 \\
        20 & 0,954 & 0,005 & 0,942 & 0,965 \\
        \textbf{50} & \textbf{0,960} & \textbf{0,005} & \textbf{0,949} & \textbf{0,968} \\
        80 & 0,959 & 0,002 & 0,954 & 0,963 \\
        100 (Czyste SVM) & 0,957 & 0,004 & 0,951 & 0,963 \\
        \bottomrule
    \end{tabular}
\end{table}

\begin{table}[H]
    \centering
    \caption{Szczegółowe wyniki dla zbioru \textbf{Wine Quality} (średnia z 25 uruchomień)}
    \begin{tabular}{ccccc}
        \toprule
        \textbf{$p_{svm}$ [\%]} & \textbf{Średnia Dokładność} & \textbf{Odch. Std.} & \textbf{Min} & \textbf{Max} \\
        \midrule
        \textbf{0 (Czyste ID3)} & \textbf{0,725} & \textbf{0,006} & \textbf{0,713} & \textbf{0,734} \\
        20 & 0,712 & 0,012 & 0,686 & 0,730 \\
        50 & 0,689 & 0,014 & 0,658 & 0,717 \\
        80 & 0,671 & 0,013 & 0,640 & 0,691 \\
        100 (Czyste SVM) & 0,662 & 0,012 & 0,636 & 0,682 \\
        \bottomrule
    \end{tabular}
\end{table}

\textbf{Wnioski:}
\begin{itemize}
    \item Na zbiorze Breast Cancer (tab.~3, rys.~\ref{fig:psvm}b) hybrydyzacja przyniosła najlepsze rezultaty. Optimum osiągnięto dla $p_{svm}=50\%$ (dokładność 0,960), co jest wynikiem wyższym niż dla czystego ID3 (0,945) oraz czystego SVM (0,957). Wskazuje to, że ensemble korzysta z różnorodności błędów popełnianych przez drzewa (nieliniowe granice decyzyjne) i SVM (liniowe granice).
    \item Na zbiorze Wine Quality (tab.~4, rys.~\ref{fig:psvm}c) obserwujemy odwrotną tendencję -- najlepsze wyniki uzyskano dla czystego ID3 ($p_{svm}=0\%$, dokładność 0,725), a zwiększanie udziału SVM systematycznie pogarszało jakość klasyfikacji (spadek do 0,662 dla $p_{svm}=100\%$). Wynika to z silnego niezbalansowania klas w tym zbiorze oraz faktu, że liniowy SVM ma trudności z separacją klas w przestrzeni cech ciągłych po dyskretyzacji.
    \item Na zbiorze Car Evaluation (rys.~\ref{fig:psvm}d) odnotowano podobny trend jak dla Wine Quality -- drastyczny spadek jakości wraz ze wzrostem udziału SVM (z 0,829 dla ID3 do 0,796 dla SVM). Relacje w tym zbiorze są silnie nieliniowe i kategoryczne, co jest naturalnym środowiskiem dla drzew decyzyjnych.
\end{itemize}

\subsection{Scenariusz 2: Wpływ liczby estymatorów ($T$)}
Zbadano wpływ rozmiaru lasu $T \in \{10, 20, 50, 100\}$ na stabilność i jakość predykcji. W eksperymencie ustalono udział SVM na $p_{svm}=50\%$ oraz regularyzację $C=1{,}0$.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{plots/scenario2_estimator_count_mushroom_data_set.png}
        \caption{Mushroom}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{plots/scenario2_estimator_count_wisconsin_breast_cancer.png}
        \caption{Breast Cancer}
    \end{subfigure}

    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{plots/scenario2_estimator_count_wine_quality___red.png}
        \caption{Wine Quality}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{plots/scenario2_estimator_count_car_evaluation.png}
        \caption{Car Evaluation}
    \end{subfigure}
    \caption{Wpływ liczby estymatorów ($T$) na średnią dokładność dla różnych zbiorów danych (dla $p_{svm}=50\%$ oraz $C=1{,}0$).}
    \label{fig:estimator_count}
\end{figure}

\textbf{Wnioski:}
\begin{itemize}
    \item Na zbiorze Mushroom (rys.~\ref{fig:estimator_count}a) obserwujemy szybką zbieżność do optimum -- już dla $T=20$ osiągamy dokładność 0,9997, a dalsze zwiększanie liczby estymatorów nie przynosi istotnej poprawy.
    \item Na zbiorze Breast Cancer (rys.~\ref{fig:estimator_count}b) zwiększanie $T$ powoduje stopniowy wzrost dokładności (z 0,958 dla $T=10$ do 0,961 dla $T=100$) oraz zmniejszenie odchylenia standardowego (z 0,007 do 0,003), co potwierdza teorię redukcji wariancji w ensemble learning.
    \item Na zbiorach Wine Quality (rys.~\ref{fig:estimator_count}c) oraz Car Evaluation (rys.~\ref{fig:estimator_count}d) zwiększanie liczby estymatorów nie poprawia dokładności (stabilizacja na poziomie odpowiednio 0,684 i 0,812), ale znacząco zmniejsza wariancję wyników -- odchylenie standardowe spada z 0,019 do 0,004 dla Wine Quality i z 0,017 do 0,010 dla Car Evaluation.
    \item Stabilizacja wyników następuje w okolicy $T=50$. Dalsze zwiększanie liczby estymatorów nie poprawia istotnie wyniku, a liniowo wydłuża czas obliczeń.
\end{itemize}

\subsection{Scenariusz 3: Wpływ regularyzacji SVM ($C$)}
Zbadano wpływ parametru $C \in \{0{,}1; 1; 10; 50\}$ dla części SVM (przy ustalonym $p_{svm}=100\%$). W eksperymencie ustalono liczbę estymatorów $T=20$.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{plots/scenario3_C_mushroom_data_set.png}
        \caption{Mushroom}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{plots/scenario3_C_wisconsin_breast_cancer.png}
        \caption{Breast Cancer}
    \end{subfigure}

    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{plots/scenario3_C_wine_quality___red.png}
        \caption{Wine Quality}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{plots/scenario3_C_car_evaluation.png}
        \caption{Car Evaluation}
    \end{subfigure}
    \caption{Wpływ parametru regularyzacji SVM ($C$) na średnią dokładność (dla $T=20$ oraz $p_{svm}=100\%$; wartości $C \in \{0{,}1; 1; 10; 50\}$).}
    \label{fig:svm_C}
\end{figure}

\textbf{Wnioski:}
\begin{itemize}
    \item Na zbiorze Mushroom (rys.~\ref{fig:svm_C}a) obserwujemy wyraźny wpływ parametru $C$ -- dla $C=0{,}1$ dokładność wynosi 0,999, natomiast dla $C \geq 10$ osiągamy perfekcyjną klasyfikację (1,000). Zbiór ten jest liniowo separowalny, więc większe $C$ pozwala na dokładniejsze dopasowanie hiperpłaszczyzny.
    \item Na zbiorze Breast Cancer (rys.~\ref{fig:svm_C}b) zwiększanie $C$ poprawia wyniki -- od 0,952 dla $C=0{,}1$ do 0,963 dla $C=50$. Wzrost jest stopniowy i stabilny, co sugeruje, że dane są dobrze separowalne liniowo, a słaba regularyzacja (wysokie $C$) nie prowadzi do przeuczenia.
    \item Na zbiorach Wine Quality (rys.~\ref{fig:svm_C}c) oraz Car Evaluation (rys.~\ref{fig:svm_C}d) wpływ parametru $C$ jest minimalny -- dokładność zmienia się odpowiednio w zakresie 0,657--0,667 oraz 0,791--0,796. Wynika to z faktu, że liniowy SVM nie jest w stanie dobrze zamodelować nieliniowych zależności w tych zbiorach, niezależnie od wartości regularyzacji.
    \item Ogólnie, zbyt małe $C$ (silna regularyzacja) powoduje niedopasowanie modelu, natomiast dla zbiorów nieliniowych zwiększanie $C$ nie przynosi istotnych korzyści.
\end{itemize}

\subsection{Analiza błędów - Macierze Pomyłek (Heatmapy)}
Poniżej przedstawiono zagregowane macierze pomyłek (suma z 25 uruchomień) dla modelu hybrydowego ($T=50$, $p_{svm}=50\%$, $C=1{,}0$). Pozwala to ocenić, które klasy są mylone najczęściej.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{plots/heatmap_Mushroom_Data_Set.png}
        \caption{Mushroom}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{plots/heatmap_Wisconsin_Breast_Cancer.png}
        \caption{Breast Cancer}
    \end{subfigure}

    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{plots/heatmap_Wine_Quality___Red.png}
        \caption{Wine Quality}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{plots/heatmap_Car_Evaluation.png}
        \caption{Car Evaluation}
    \end{subfigure}
    \caption{Zagregowane macierze pomyłek (heatmapy) dla $T=50$, $p_{svm}=50\%$, $C=1{,}0$.}
\end{figure}

Wnioski:
Na zbiorze \textit{Car Evaluation} najwięcej pomyłek występuje przy klasyfikacji klasy rzadkiej ("vgood") jako klasy częstej ("acc"). Jest to typowy efekt dla niezbalansowanych zbiorów danych. Hybrydyzacja z SVM nie rozwiązała tego problemu w stopniu zadowalającym, gdyż liniowy SVM ma tendencję do faworyzowania klas większościowych.

\section{Analiza nadmiernego dopasowania (Overfitting)}
W celu oceny zjawiska przeuczenia porównano dokładność na zbiorze treningowym i testowym.

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{plots/overfitting_mushroom_data_set.png}
        \caption{Mushroom}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{plots/overfitting_wisconsin_breast_cancer.png}
        \caption{Breast Cancer}
    \end{subfigure}

    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{plots/overfitting_wine_quality___red.png}
        \caption{Wine Quality}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{plots/overfitting_car_evaluation.png}
        \caption{Car Evaluation}
    \end{subfigure}
    \caption{Porównanie dokładności na zbiorze treningowym i testowym (Train vs Test) dla $T=50$, $p_{svm}=50\%$, $C=1{,}0$.}
    \label{fig:overfitting}
\end{figure}

Wniosek: Obserwujemy wyraźne nadmierne dopasowanie. Drzewa ID3 mają tendencję do budowania bardzo głębokich struktur (brak przycinania w implementacji). Zastosowanie lasu (Bagging) zmniejszyło ten efekt względem pojedynczego drzewa (gdzie różnica wynosiła ponad 20 p.p.), ale go nie wyeliminowało. Sugeruje to konieczność wprowadzenia ograniczenia głębokości drzewa (\texttt{max\_depth}) w przyszłych pracach.

\section{Podsumowanie i wnioski końcowe}
Zrealizowany projekt pozwolił na zbadanie właściwości hybrydowego lasu klasyfikacyjnego. Główne wnioski z badań są następujące:
\begin{enumerate}
    \item \textbf{Skuteczność hybrydyzacji:} łączenie SVM i ID3 ma sens tylko na zbiorach, które posiadają cechy częściowo separowalne liniowo, a częściowo wymagające nieliniowych podziałów (jak \textit{Breast Cancer}). Na zbiorach typowo dyskretnych (\textit{Car Evaluation}) dodanie SVM pogarsza wyniki.
    \item \textbf{Wrażliwość na dane:} autorska implementacja ID3 działa poprawnie i dorównuje rozwiązaniom bibliotecznym na danych dyskretnych.
    \item \textbf{Czego się nauczyliśmy:} realizacja projektu pozwoliła nam zrozumieć praktyczne różnice między modelami generatywnymi (drzewa) a dyskryminacyjnymi (SVM). Zrozumieliśmy również, jak kluczowa dla algorytmów zespołowych jest różnorodność estymatorów bazowych - bez wprowadzenia losowania cech (\textit{Random Subspace}) nasz las hybrydowy nie osiągałby lepszych wyników niż pojedynczy klasyfikator.
\end{enumerate}

\end{document}